{
 "metadata": {
  "name": "",
  "signature": "sha256:e3812c8fcb68c4ce143aeafb410d0226dbb617720353389311d1396447ed3c86"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This work is much pimped from this example of scikit-learn's documentation: \n",
      "# http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html\n",
      "\"\"\"\n",
      "==============================================================\n",
      "Restricted Boltzmann Machine features for digit classification\n",
      "==============================================================\n",
      "\n",
      "For greyscale image data where pixel values can be interpreted as degrees of\n",
      "blackness on a white background, like handwritten digit recognition, the\n",
      "Bernoulli Restricted Boltzmann machine model (:class:`BernoulliRBM\n",
      "<sklearn.neural_network.BernoulliRBM>`) can perform effective non-linear\n",
      "feature extraction.\n",
      "\n",
      "In order to learn good latent representations from a small dataset, we\n",
      "artificially generate more labeled data by perturbing the training data with\n",
      "linear shifts of 1 pixel in each direction.\n",
      "\n",
      "This example shows how to build a classification pipeline with a BernoulliRBM\n",
      "feature extractor and a :class:`LogisticRegression\n",
      "<sklearn.linear_model.LogisticRegression>` classifier. The hyperparameters\n",
      "of the entire model (learning rate, hidden layer size, regularization)\n",
      "were optimized by grid search, but the search is not reproduced here because\n",
      "of runtime constraints.\n",
      "\n",
      "Logistic regression on raw pixel values is presented for comparison. The\n",
      "example shows that the features extracted by the BernoulliRBM help improve the\n",
      "classification accuracy.\n",
      "\"\"\"\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "# print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve, Guillaume Chevalier\n",
      "# License: BSD\n",
      "\n",
      "import pickle\n",
      "import os.path\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import Image\n",
      "import scipy.ndimage\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Defining functions & misc.\n",
      "\n",
      "perceptron_width = 16  # Must be a multiple of 8\n",
      "perceptron_count = perceptron_width * perceptron_width\n",
      "pickles_suffix = \"_{0}x{0}.pickle\".format(perceptron_width)\n",
      "\n",
      "hidden_layer_width = 15\n",
      "hidden_layer_count = hidden_layer_width * hidden_layer_width\n",
      "\n",
      "def nudge_dataset(X, Y):\n",
      "    \"\"\"\n",
      "    This produces a dataset 5 times bigger than the original one,\n",
      "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
      "    \"\"\"\n",
      "    direction_vectors = [\n",
      "        [[0, 1, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [1, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 1, 0]]]\n",
      "\n",
      "    shift = lambda x, w: convolve(x.reshape((perceptron_width, perceptron_width)), mode='constant',\n",
      "                                  weights=w).ravel()\n",
      "    X = np.concatenate([X] +\n",
      "                       [np.apply_along_axis(shift, 1, X, vector)\n",
      "                        for vector in direction_vectors])\n",
      "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
      "    return X, Y\n",
      "\n",
      "def resample_img(img, currentWidth=128, newWidth=perceptron_width):\n",
      "    ratio = currentWidth/newWidth\n",
      "    if (ratio<1):\n",
      "        print(\"1\")\n",
      "        print (img)\n",
      "        print(scipy.ndimage.zoom(img, 2, order=1))\n",
      "        \n",
      "        # raise \"one.\" #TODO: REM\n",
      "        return scipy.ndimage.zoom(img, 2, order=1)  #TODO: replace \"2\"\n",
      "    else:\n",
      "        return img.reshape([newWidth, ratio, newWidth, ratio]).mean(3).mean(1)\n",
      "\n",
      "# Loading more custom training images\n",
      "def loadgrayscale_img(path=\"7.jpg\", currentWidth=8, wantedWidth=perceptron_width):\n",
      "    im = Image.open(path)\n",
      "    img = np.array(im)\n",
      "    \n",
      "    def iavg(a):\n",
      "        return (255.0 - (np.average(a)))/255.0\n",
      "    \n",
      "    grayscale_lrg = np.zeros((img.shape[0], img.shape[1]))\n",
      "    for rownum in range(len(img)):\n",
      "       for colnum in range(len(img[rownum])):\n",
      "          grayscale_lrg[rownum][colnum] = iavg(img[rownum][colnum])\n",
      "    \n",
      "    return resample_img(grayscale_lrg, currentWidth, newWidth=wantedWidth)\n",
      "\n",
      "def load_fnt_dataset():\n",
      "    images = []\n",
      "    labels = []\n",
      "    \n",
      "    for i in xrange(0+1, 1016+1):\n",
      "        for x in xrange(0+1, 9+1+1):    \n",
      "            folder_name = \"Sample{0:03d}\".format(x)\n",
      "            file_name_prefix = \"img{0:03d}-\".format(x)\n",
      "        \n",
      "            file_name = \"{0}{1:05d}.png\".format(file_name_prefix, i)\n",
      "            img_path=\"fnt_dataset\\{}\\{}\".format(folder_name, file_name)\n",
      "            \n",
      "            pickle_file_name = \"{}{}\".format(file_name[0:-4], pickles_suffix)\n",
      "            pickle_path = \"dataset_pickles\\{}\".format(pickle_file_name)\n",
      "            \n",
      "            if (os.path.exists(pickle_path)):\n",
      "                with open(pickle_path) as f:\n",
      "                    this_data_img, this_target_label = pickle.load(f)\n",
      "            else:\n",
      "                this_data_img = loadgrayscale_img(path=img_path, currentWidth=128, wantedWidth=perceptron_width).flatten()\n",
      "                this_target_label = x-1\n",
      "                with open(pickle_path, 'w') as f:\n",
      "                    pickle.dump([this_data_img, this_target_label], f)\n",
      "            \n",
      "            images.append(this_data_img)\n",
      "            labels.append(this_target_label)\n",
      "            \n",
      "    return images, labels\n",
      "\n",
      "def load_default_dataset():\n",
      "    images = []\n",
      "    labels = []\n",
      "    \n",
      "    pickle_path = \"dataset_pickles\\dflt_dataset{}\".format(pickles_suffix)\n",
      "    if (os.path.exists(pickle_path)):\n",
      "        with open(pickle_path) as f:\n",
      "            print()\n",
      "            #TODO: REM THIS\n",
      "            # images, labels = pickle.load(f)\n",
      "    else:\n",
      "        digits_set = datasets.load_digits()\n",
      "        original_images = np.asarray(digits_set.data, 'float32')\n",
      "\n",
      "        if(perceptron_width != 8):  # Resampling if needed\n",
      "            xi=0\n",
      "            for x in original_images:\n",
      "                this_image = resample_img(x.reshape(8, 8), currentWidth=8, newWidth=perceptron_width).flatten()\n",
      "                images.append(this_image)\n",
      "                print(x.reshape(8, 8))\n",
      "                print(this_image.reshape(16, 16))\n",
      "                xi += 1\n",
      "        images = (images - np.min(images, 0)) / (np.max(images, 0) + 0.0001)  # 0-1 scaling\n",
      "        labels = digits_set.target\n",
      "        \n",
      "        with open(pickle_path, 'w') as f:\n",
      "            #TODO: uncomment. \n",
      "            #pickle.dump([images, labels], f)\n",
      "            print()\n",
      "    \n",
      "    return images, labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Load Data\n",
      "\n",
      "fnt_dataset_path = 'fnt_dataset{}'.format(pickles_suffix)\n",
      "if (os.path.exists(fnt_dataset_path)):\n",
      "    with open(fnt_dataset_path) as f:\n",
      "        X, Y = pickle.load(f)\n",
      "else: \n",
      "    print(\"Loading default dataset...\")\n",
      "    x_dflt, y_dflt = load_default_dataset()\n",
      "    print(x_dflt[0])\n",
      "    print(x_dflt[0].reshape(perceptron_width, perceptron_width))\n",
      "    \n",
      "    print(\"Loading fnt dataset...\")\n",
      "    x_fnt, y_fnt = load_fnt_dataset()\n",
      "    print(x_fnt[0].reshape(perceptron_width, perceptron_width))\n",
      "\n",
      "    print(\"Appending datasets...\")\n",
      "    X, Y = np.append(x_dflt, x_fnt, axis=0), np.append(y_dflt, y_fnt, axis=0)\n",
      "\n",
      "    # Saving the objects:\n",
      "    with open(fnt_dataset_path, 'w') as f:\n",
      "        pickle.dump([X, Y], f)\n",
      "\n",
      "print(\"train_test_split...\")\n",
      "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "\n",
      "# Models used\n",
      "print(\"RBM & Classifier inits...\")\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(random_state=1, verbose=True)\n",
      "\n",
      "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
      "\n",
      "print(\"Setup Done:\")\n",
      "print(\"Total images: {}\".format(len(X)))\n",
      "print(\"Total training images: {}\".format(len(X_train)))\n",
      "print(\"Total testing images: {}\".format(len(X_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading default dataset...\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[  0.   0.   5.  13.   9.   1.   0.   0.]\n",
        " [  0.   0.  13.  15.  10.  15.   5.   0.]\n",
        " [  0.   3.  15.   2.   0.  11.   8.   0.]\n",
        " [  0.   4.  12.   0.   0.   8.   8.   0.]\n",
        " [  0.   5.   8.   0.   0.   9.   8.   0.]\n",
        " [  0.   4.  11.   0.   1.  12.   7.   0.]\n",
        " [  0.   2.  14.   5.  10.  12.   0.   0.]\n",
        " [  0.   0.   6.  13.  10.   0.   0.   0.]]\n",
        "[[  0.           0.           0.           2.           4.33333349\n",
        "    7.66666651  11.39999962  11.9333334   10.0666666    7.4000001\n",
        "    3.66666675   0.86666667   0.40000001   0.           0.           0.        ]\n",
        " [  0.           0.           0.           3.49333334   7.56888866\n",
        "   10.46666622  12.89333344  12.74222183  10.65777779   9.07999992\n",
        "    8.17777824   6.84000015   4.41333342   2.17777777   1.08888888   0.        ]\n",
        " [  0.           0.           0.           4.98666668  10.80444431\n",
        "   13.26666641  14.3866663   13.55111122  11.24888897  10.76000023\n",
        "   12.68888855  12.81333351   8.42666626   4.35555553   2.17777777   0.        ]\n",
        " [  0.           0.56         1.12         6.23999977  12.11999989\n",
        "   12.46666622  10.60000038   8.78666687   7.01333332   7.48000002\n",
        "   10.9333334   12.43999958   9.07999992   5.78666687   2.89333344   0.        ]\n",
        " [  0.           1.21333337   2.42666674   7.45333338  13.11555576\n",
        "   11.0666666    5.9333334    3.09333324   1.97333336   3.37333322\n",
        "    8.13333321  11.0088892    9.17333317   7.09333324   3.54666662   0.        ]\n",
        " [  0.           1.55555558   3.11111116   7.5999999   12.57777786\n",
        "    9.77777767   3.86666656   0.97777778   0.35555556   2.           6.66666651\n",
        "    9.73333359   8.80000019   7.4666667    3.73333335   0.        ]\n",
        " [  0.           1.77333331   3.54666662   7.32000017  11.42666626\n",
        "    8.53333378   2.83999991   0.29333332   0.10666667   1.72000003\n",
        "    5.73333311   8.52000046   8.23999977   7.4666667    3.73333335   0.        ]\n",
        " [  0.           1.99111116   3.98222232   6.9333334   10.04444408\n",
        "    7.28888893   2.18666673   0.           0.           1.65333331\n",
        "    5.51111126   8.23111153   8.10666656   7.4666667    3.73333335   0.        ]\n",
        " [  0.           2.20888901   4.41777802   6.4666667    8.48888874\n",
        "    6.04444456   1.81333339   0.           0.           1.74666667\n",
        "    5.82222223   8.63555527   8.29333305   7.4666667    3.73333335   0.        ]\n",
        " [  0.           2.24000001   4.48000002   6.32000017   8.09333324\n",
        "    5.73333311   1.72000003   0.05333333   0.14666666   2.07999992\n",
        "    6.4666667    9.35999966   8.52000046   7.28000021   3.6400001    0.        ]\n",
        " [  0.           2.02222228   4.04444456   6.5999999    9.24444485\n",
        "    6.66666651   2.           0.17777778   0.48888889   2.73333335\n",
        "    7.55555534  10.51111126   8.80000019   6.84444427   3.42222214   0.        ]\n",
        " [  0.           1.74222219   3.48444438   6.80000019  10.37777805\n",
        "    7.82222223   2.81333327   1.07555556   1.79111111   4.15999985\n",
        "    8.73333359  11.20888901   8.43999958   5.66222239   2.83111119   0.        ]\n",
        " [  0.           1.30666661   2.61333323   6.80000019  11.46666622\n",
        "    9.53333378   4.96000004   3.90666676   5.49333334   7.51999998\n",
        "   10.13333321  10.77333355   6.48000002   2.61333323   1.30666661   0.        ]\n",
        " [  0.           0.87111109   1.74222219   6.50666666  11.92000008\n",
        "   10.82222176   7.11999989   6.72444439   8.80888844  10.23999977\n",
        "   10.80000019   9.70666695   4.48000002   0.           0.           0.        ]\n",
        " [  0.           0.43555555   0.87111109   4.45333338   8.56000042\n",
        "    9.57777786   9.35999966   9.4622221    9.80444431   9.11999989\n",
        "    7.0666666    4.85333347   2.24000001   0.           0.           0.        ]\n",
        " [  0.           0.           0.           2.4000001    5.19999981\n",
        "    8.33333302  11.60000038  12.19999981  10.80000019   8.           3.33333325\n",
        "    0.           0.           0.           0.           0.        ]]\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "exceptions must be old-style classes or derived from BaseException, not str",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-b157721b8044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading default dataset...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mx_dflt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dflt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_default_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dflt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dflt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperceptron_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperceptron_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-4-b1e531d45674>\u001b[0m in \u001b[0;36mload_default_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moriginal_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mthis_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrentWidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewWidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperceptron_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-4-b1e531d45674>\u001b[0m in \u001b[0;36mresample_img\u001b[1;34m(img, currentWidth, newWidth)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[1;34m\"one.\"\u001b[0m \u001b[1;31m#TODO: REM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#TODO: replace \"2\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: exceptions must be old-style classes or derived from BaseException, not str"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "rbm.learning_rate = 0.06\n",
      "rbm.n_iter = 25 #TODO: before was set at 20. \n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "rbm.n_components = hidden_layer_count\n",
      "logistic.C = 6000.0\n",
      "\n",
      "# Training RBM-Logistic Pipeline\n",
      "classifier.fit(X_train, Y_train)\n",
      "\n",
      "# Training Logistic regression\n",
      "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
      "logistic_classifier.fit(X_train, Y_train)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        classifier.predict(X_test))))\n",
      "\n",
      "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        logistic_classifier.predict(X_test))))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Plotting RBM hidden layer's weight matrix\n",
      "\n",
      "plt.figure(figsize=(4.2, 4))\n",
      "for i, comp in enumerate(rbm.components_):\n",
      "    plt.subplot(hidden_layer_width, hidden_layer_width, i + 1)\n",
      "    plt.imshow(comp.reshape((perceptron_width, perceptron_width)), cmap=plt.cm.gray_r,\n",
      "               interpolation='nearest')\n",
      "    plt.xticks(())\n",
      "    plt.yticks(())\n",
      "plt.suptitle(\"RBM's {} hidden layer's weights matrixes\".format(hidden_layer_count), fontsize=16)\n",
      "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Single Prediction\n",
      "\n",
      "number = 0\n",
      "number_version = 74\n",
      "\n",
      "folder_name = \"Sample{0:03d}\".format(number+1)\n",
      "file_name_prefix = \"img{0:03d}-\".format(number+1)\n",
      "file_name = \"{0}{1:05d}.png\".format(file_name_prefix, number_version)\n",
      "imgPerso = loadgrayscale_img(path=\"fnt_dataset\\{}\\{}\".format(folder_name, file_name), currentWidth=128, wantedWidth=perceptron_width)\n",
      "            \n",
      "plt.imshow(imgPerso, cmap=plt.cm.gray_r,\n",
      "           interpolation='nearest')\n",
      "plt.suptitle('Predicted value: {} \\n Real Value: {}'.format(logistic_classifier.predict(imgPerso.flatten())[0], number), fontsize=36)\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ii = 2000\n",
      "imgg = X_test[i]\n",
      "imggy = Y_test[i]\n",
      "\n",
      "plt.imshow(imgg.reshape(perceptron_width, perceptron_width), cmap=plt.cm.gray_r,\n",
      "           interpolation='nearest')\n",
      "plt.suptitle('Value: {}'.format(imggy), fontsize=36)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}